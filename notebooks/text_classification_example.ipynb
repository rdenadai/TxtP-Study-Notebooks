{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_classification_example.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/rdenadai/TxtP-Study-Notebooks/blob/master/notebooks/text_classification_example.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "WGxO__uG47K5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## AnÃ¡lise e ValidaÃ§Ã£o de Textos em PortuguÃªs\n"
      ]
    },
    {
      "metadata": {
        "id": "AzVNkORP5dvZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### ReferÃªncias:\n",
        "\n",
        " - [NLTK](http://www.nltk.org/howto/portuguese_en.html)\n",
        " - [spaCy](https://spacy.io/usage/spacy-101)\n",
        " - [Utilizando processamento de linguagem natural para criar uma sumarizaÃ§Ã£o automÃ¡tica de textos](https://medium.com/@viniljf/utilizando-processamento-de-linguagem-natural-para-criar-um-sumariza%C3%A7%C3%A3o-autom%C3%A1tica-de-textos-775cb428c84e)\n",
        " - [Latent Semantic Analysis (LSA) for Text Classification Tutorial](http://mccormickml.com/2016/03/25/lsa-for-text-classification-tutorial/)\n",
        " - [Topic Modeling with LSA, PLSA, LDA & lda2Vec](https://medium.com/nanonets/topic-modeling-with-lsa-psla-lda-and-lda2vec-555ff65b0b05)\n",
        " - [Unsupervised Emotion Detection from Text using Semantic and Syntactic Relations](http://www.cse.yorku.ca/~aan/research/paper/Emo_WI10.pdf)"
      ]
    },
    {
      "metadata": {
        "id": "fJl2_xgi5M4C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### InstalaÃ§Ã£o"
      ]
    },
    {
      "metadata": {
        "id": "6gSt861Txvl1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "outputId": "b1efd8f4-9c35-45c3-841c-84ea96201fb2"
      },
      "cell_type": "code",
      "source": [
        "!pip install -U spacy\n",
        "!python -m spacy download en\n",
        "!python -m spacy download pt\n",
        "# !pip install feedparser"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: spacy in /usr/local/lib/python3.6/dist-packages (2.0.12)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.14.6)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<0.29,>=0.28 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.28.0)\n",
            "Requirement already satisfied, skipping upgrade: cymem<1.32,>=1.30 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.31.2)\n",
            "Requirement already satisfied, skipping upgrade: preshed<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: thinc<6.11.0,>=6.10.3 in /usr/local/lib/python3.6/dist-packages (from spacy) (6.10.3)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n",
            "Requirement already satisfied, skipping upgrade: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.35)\n",
            "Requirement already satisfied, skipping upgrade: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.8.2)\n",
            "Requirement already satisfied, skipping upgrade: regex==2017.4.5 in /usr/local/lib/python3.6/dist-packages (from spacy) (2017.4.5)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.18.4)\n",
            "Requirement already satisfied, skipping upgrade: msgpack<1.0.0,>=0.5.6 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.3->spacy) (0.5.6)\n",
            "Requirement already satisfied, skipping upgrade: msgpack-numpy<1.0.0,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.3->spacy) (0.4.4.1)\n",
            "Requirement already satisfied, skipping upgrade: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.3->spacy) (0.9.0.1)\n",
            "Requirement already satisfied, skipping upgrade: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.3->spacy) (1.10.11)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.3->spacy) (4.26.0)\n",
            "Requirement already satisfied, skipping upgrade: six<2.0.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.3->spacy) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.22)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2018.8.24)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.6)\n",
            "Requirement already satisfied, skipping upgrade: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc<6.11.0,>=6.10.3->spacy) (0.9.0)\n",
            "Collecting en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz (37.4MB)\n",
            "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37.4MB 39.2MB/s \n",
            "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
            "  Running setup.py install for en-core-web-sm ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25hSuccessfully installed en-core-web-sm-2.0.0\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "\n",
            "    You can now load the model via spacy.load('en')\n",
            "\n",
            "Collecting pt_core_news_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.0.0/pt_core_news_sm-2.0.0.tar.gz#egg=pt_core_news_sm==2.0.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.0.0/pt_core_news_sm-2.0.0.tar.gz (38.7MB)\n",
            "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38.7MB 23.1MB/s \n",
            "\u001b[?25hInstalling collected packages: pt-core-news-sm\n",
            "  Running setup.py install for pt-core-news-sm ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25hSuccessfully installed pt-core-news-sm-2.0.0\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/pt_core_news_sm -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/pt\n",
            "\n",
            "    You can now load the model via spacy.load('pt')\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PcT7xbKKo55-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "25f2a2ec-79ca-41dc-88aa-fd64c042c73f"
      },
      "cell_type": "code",
      "source": [
        "# Download Oplexicon\n",
        "!rm -rf wget-log*\n",
        "!rm -rf oplexicon_v3.0\n",
        "!wget -O oplexicon_v3.0.zip https://github.com/rdenadai/sentiment-analysis-2018-president-election/blob/master/dataset/oplexicon_v3.0.zip?raw=true\n",
        "!unzip oplexicon_v3.0.zip\n",
        "!ls -lh"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Redirecting output to â€˜wget-logâ€™.\n",
            "Archive:  oplexicon_v3.0.zip\n",
            "  inflating: oplexicon_v3.0/lexico_v3.0.txt  \n",
            "  inflating: oplexicon_v3.0/README   \n",
            "total 120K\n",
            "drwxr-xr-x 2 root root 4.0K Oct  6 00:48 oplexicon_v3.0\n",
            "-rw-r--r-- 1 root root 102K Oct  6 00:48 oplexicon_v3.0.zip\n",
            "drwxr-xr-x 2 root root 4.0K Sep 28 23:32 sample_data\n",
            "-rw-r--r-- 1 root root 1.6K Oct  6 00:48 wget-log\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mVxM4zTo5QSB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ]
    },
    {
      "metadata": {
        "id": "HLlEa6uEyX11",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "45d136e2-6b07-4295-d589-6e9979ffbe47"
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('rslp')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('floresta')\n",
        "nltk.download('mac_morpho')\n",
        "nltk.download('machado')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('words')\n",
        "\n",
        "import concurrent.futures\n",
        "import codecs\n",
        "import re\n",
        "import pprint\n",
        "from random import shuffle\n",
        "from string import punctuation\n",
        "import copy\n",
        "from unicodedata import normalize\n",
        "\n",
        "import numpy as np\n",
        "from scipy.sparse.linalg import svds\n",
        "from scipy.linalg import svd\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy.lang.pt.lemmatizer import LOOKUP\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances\n",
        "from sklearn.utils.extmath import randomized_svd\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.corpus import floresta as flt\n",
        "from nltk.corpus import machado as mch\n",
        "from nltk.corpus import mac_morpho as mcm\n",
        "\n",
        "\n",
        "nlp = spacy.load('pt')\n",
        "pp = pprint.PrettyPrinter(indent=4)\n",
        "stemmer = nltk.stem.RSLPStemmer()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Package rslp is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]   Package floresta is already up-to-date!\n",
            "[nltk_data] Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]   Package mac_morpho is already up-to-date!\n",
            "[nltk_data] Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]   Package machado is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z0CGK0ftshPG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Functions"
      ]
    },
    {
      "metadata": {
        "id": "pOMbwFd3sd31",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def remover_acentos(txt):\n",
        "    return normalize('NFKD', txt).encode('ASCII', 'ignore').decode('ASCII')\n",
        "\n",
        "\n",
        "def load_oplexicon_data(filename):\n",
        "    spacy_conv = {\n",
        "        'adj': 'ADJ',\n",
        "        'n': 'NOUN',\n",
        "        'vb': 'VERB',\n",
        "        'det': 'DET',\n",
        "        'emot': 'EMOT',\n",
        "        'htag': 'HTAG'\n",
        "    }\n",
        "    \n",
        "    data = {}\n",
        "    with codecs.open(filename, 'r', 'UTF-8') as hf:\n",
        "        lines = hf.readlines()\n",
        "        for line in lines:\n",
        "            info = line.lower().split(',')\n",
        "            if len(info[0].split()) <= 1:\n",
        "                info[1] = [spacy_conv.get(tag) for tag in info[1].split()]\n",
        "                word, tags, sent = info[:3]\n",
        "                if 'HTAG' not in tags and 'EMOT' not in tags:\n",
        "                    word = remover_acentos(word.replace('-se', ''))\n",
        "                    word = LOOKUP.get(word, word)\n",
        "                    # stem = stemmer.stem(word)\n",
        "                    if word in data:\n",
        "                        data[word] += [{\n",
        "                            'word': [word],\n",
        "                            'tags': tags,\n",
        "                            'sentiment': sent\n",
        "                        }]\n",
        "                    else:\n",
        "                        data[word] = [{\n",
        "                            'word': [word],\n",
        "                            'tags': tags,\n",
        "                            'sentiment': sent\n",
        "                        }]\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FwSQhPMk5Scp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Usage"
      ]
    },
    {
      "metadata": {
        "id": "mQzbtaNhy5Y4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "edab57d2-0757-41c5-e0ed-702a08eda599"
      },
      "cell_type": "code",
      "source": [
        "frase = u\"Gostaria de saber mais informaÃ§Ãµes sobre a Amazon. Uma excelente loja de produtos online!\".lower()\n",
        "doc = nlp(remover_acentos(frase))\n",
        "pp.pprint([(w.text, w.pos_) for w in doc])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   ('gostaria', 'VERB'),\n",
            "    ('de', 'ADP'),\n",
            "    ('saber', 'VERB'),\n",
            "    ('mais', 'ADV'),\n",
            "    ('informacoes', 'NOUN'),\n",
            "    ('sobre', 'ADP'),\n",
            "    ('a', 'DET'),\n",
            "    ('amazon', 'NOUN'),\n",
            "    ('.', 'PUNCT'),\n",
            "    ('uma', 'DET'),\n",
            "    ('excelente', 'ADJ'),\n",
            "    ('loja', 'NOUN'),\n",
            "    ('de', 'ADP'),\n",
            "    ('produtos', 'NOUN'),\n",
            "    ('online', 'ADJ'),\n",
            "    ('!', 'PUNCT')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F--aytOy3gL_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "4c630bed-689f-4ac1-e127-3cb9820d2f1f"
      },
      "cell_type": "code",
      "source": [
        "opx = load_oplexicon_data('oplexicon_v3.0/lexico_v3.0.txt')\n",
        "print('Oplexicon size: ', len(opx))\n",
        "print('Examples: ')\n",
        "\n",
        "view = opx.items()\n",
        "pp.pprint(list(view)[:7])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Oplexicon size:  15958\n",
            "Examples: \n",
            "[   ('ab-rogar', [{'sentiment': '-1', 'tags': ['VERB'], 'word': ['ab-rogar']}]),\n",
            "    ('ababadar', [{'sentiment': '0', 'tags': ['VERB'], 'word': ['ababadar']}]),\n",
            "    (   'ababelar',\n",
            "        [   {'sentiment': '-1', 'tags': ['VERB'], 'word': ['ababelar']},\n",
            "            {'sentiment': '1', 'tags': ['VERB'], 'word': ['ababelar']}]),\n",
            "    ('abacanar', [{'sentiment': '1', 'tags': ['VERB'], 'word': ['abacanar']}]),\n",
            "    ('abacinar', [{'sentiment': '1', 'tags': ['VERB'], 'word': ['abacinar']}]),\n",
            "    (   'abafar',\n",
            "        [   {'sentiment': '-1', 'tags': ['ADJ'], 'word': ['abafar']},\n",
            "            {'sentiment': '-1', 'tags': ['ADJ'], 'word': ['abafar']},\n",
            "            {'sentiment': '-1', 'tags': ['ADJ'], 'word': ['abafar']},\n",
            "            {'sentiment': '-1', 'tags': ['ADJ'], 'word': ['abafar']},\n",
            "            {'sentiment': '-1', 'tags': ['VERB'], 'word': ['abafar']}]),\n",
            "    (   'abafante',\n",
            "        [   {'sentiment': '-1', 'tags': ['ADJ'], 'word': ['abafante']},\n",
            "            {'sentiment': '-1', 'tags': ['ADJ'], 'word': ['abafante']}])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AcajLBiFm3N1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ALEGRIA = ['abundante', 'acalmar', 'aceitÃ¡vel', 'aclamar', 'aconchego', 'adesÃ£o', 'admirar', 'adorar', 'afÃ¡vel', 'afeiÃ§Ã£o', 'afeto', 'afortunado', 'agradar', 'ajeitar', 'alÃ­vio', 'amabilidade', 'amado', 'amar', 'amÃ¡vel', 'amenizar', 'ameno', 'amigÃ¡vel', 'amistoso', ' amizade', ' amor', ' animaÃ§Ã£o', ' Ã¢nimo', 'anseio', 'Ã¢nsia', 'ansioso', 'apaixonado', 'apaziguar', 'aplausos', 'apoiar', 'aprazer', 'apreciar', 'aprovaÃ§Ã£o', 'aproveitar', 'ardor', 'armirar', 'arrumar', 'atraÃ§Ã£o', 'atraente', 'atrair', 'avidamente', 'avidez', 'Ã¡vido', 'belo', 'bem-estar', 'beneficÃªncia', 'beneficiador', 'benefÃ­cio', 'benÃ©fico', 'benevocÃªncia', 'benignamente', 'benÃ­gno', 'bom', 'bondade', 'bondoso', 'bonito', 'brilhante', 'brincadeira', 'calma', 'calor', 'caridade', 'caridoso', 'carinho', 'cativar', 'charme', 'cheery', 'clamar', 'cofortar', 'coleguismo', 'comÃ©dia', 'cÃ´mico', 'comover', 'compaixÃ£o', 'companheirismo', 'compatibilidade', 'compatÃ­vel', 'complacÃªncia', 'completar', 'compreensÃ£o', 'conclusÃ£o', 'concretizaÃ§Ã£o', 'condescendÃªncia', 'confianÃ§a', 'confortante', 'congratulaÃ§Ã£o', 'conquistar', 'consentir', 'consideraÃ§Ã£o', 'consolaÃ§Ã£o', 'contentamento', 'coragem', 'cordial', 'considerar', 'consolo', 'contente', 'cuidadoso', 'cumplicidade', 'dedicaÃ§Ã£o', 'deleitado', 'delicadamente', 'delicadeza', 'delicado', 'desejar', 'despreocupaÃ§Ã£o', 'devoÃ§Ã£o', 'devoto', 'diversÃ£o', 'divertido', 'encantar', 'elogiado', 'emoÃ§Ã£o', 'emocionante', 'emotivo', 'empatia', 'empÃ¡tico', 'empolgaÃ§Ã£o', 'enamorar', 'encantado', 'encorajado', 'enfeitar', 'engraÃ§ado', 'entendimento', 'entusiasmadamente', 'entusiÃ¡stico', 'esperanÃ§a', 'esplendor', 'estima', 'estimar', 'estimulante', 'euforia', 'eufÃ³rico', 'euforizante', 'exaltar', 'excelente', 'excitar', 'expansivo', 'extasiar', 'exuberante', 'exultar', 'fÃ£', 'facilitar', 'familiaridade', 'fascinaÃ§Ã£o', 'fascÃ­nio', 'favor', 'favorecer', 'favorito', 'felicidade', 'feliz', 'festa', 'festejar', 'festivo', 'fidelidade', 'fiel', 'filantropia', 'filantrÃ³pico', 'fraterno', 'ganhar', 'generosidade', 'generoso', 'gentil', 'glÃ³ria', 'glorificar', 'gostar', 'gostoso', 'gozar', 'gratificante', 'grato', 'hilariante', 'honra', 'humor', 'impressionar', 'incentivar', 'incentivo', 'inclinaÃ§Ã£o', 'incrÃ­vel', 'inspirar', 'interessar', 'interesse', 'irmandade', 'jovial', 'jubilante', 'jÃºbilo', 'lealdade', 'legÃ­timo', 'leveza', 'louvar', 'louvÃ¡vel', 'louvavelmente', 'lucrativo', 'lucro', 'maravilhoso', 'melhor', 'obter', 'obteve', 'ode', 'orgulho', 'paixÃ£o', 'parabenizar', 'paz', 'piedoso', 'positivo', 'prazenteiro', 'prazer', 'predileÃ§Ã£o', 'preencher', 'preferÃªncia', 'preferido', 'promissor', 'prosperidade', 'proteÃ§Ã£o', 'proteger', 'revigorar', 'simpÃ¡tico', 'vantajoso', 'protetor', 'risada', 'sobrevivÃªncia', 'vencedor', 'proveito', 'risonho', 'sobreviver', 'veneraÃ§Ã£o', 'provilÃ©gio', 'romÃ¢ntico', 'sorte', 'ventura', 'querer', 'romantismo', 'sortudo', 'vida', 'radiante', 'saciar', 'sucesso', 'vigor', 'realizar', 'saciÃ¡vel', 'surpreender', 'virtude', 'recomendÃ¡vel', 'satisfaÃ§Ã£o', 'tenro', 'virtuoso', 'reconhecer', 'satisfatoriamente', 'ternura', 'vitÃ³ria', 'recompensa', 'satisfatÃ³rio', 'torcer', 'vitorioso', 'recrear', 'satisfazer', 'tranquilo', 'viver', 'recreativo', 'satisfeito', 'tranquilo', 'vivo', 'recreaÃ§Ã£o', 'seduÃ§Ã£o', 'triunfo', 'zelo', 'regozijar', 'seduzir', 'triunfal', 'zeloso', 'respeitar', 'sereno', 'triunfante', 'ressuscitar', 'simpaticamente', 'vantagem',]\n",
        "DESGOSTO = ['abominÃ¡vel', 'adoentado', 'amargamente', 'antipatia', 'antipÃ¡tico', 'asco', 'asqueroso', 'aversÃ£o', 'chatear', 'chateaÃ§Ã£o', 'desagrado', 'desagradÃ¡vel', 'desprezÃ­vel', 'detestÃ¡vel', 'doente', 'doenÃ§a', 'enfermidade', 'enjoativo', 'enjoo', 'enjÃ´o', 'feio', 'fÃ©tido', 'golfar', 'grave', 'gravidade', 'grosseiro', 'grosso', 'horrÃ­vel', 'ignÃ³bil', 'ilegal', 'incomodar', 'incÃ´mdo', 'indecente', 'indisposiÃ§Ã£o', 'indisposto', 'inescrupuloso', 'maldade', 'maldoso', 'malvado', 'mau', 'nauseabundo', 'nauseante', 'nausear', 'nauseoso', 'nojento', 'nojo', 'nÃ¡usea', 'obsceno', 'obstruir', 'obstruÃ§Ã£o', 'ofensivo', 'patÃ©tico', 'perigoso', 'repelente', 'repelir', 'repugnante', 'repulsa', 'repulsivo', 'repulsÃ£o', 'rude', 'sujeira', 'sujo', 'terrivelmente', 'terrÃ­vel', 'torpe', 'travesso', 'travessura', 'ultrajante', 'vil', 'vomitar', 'vÃ´mito',]\n",
        "MEDO = ['abominÃ¡vel', 'afugentar', 'alarmar', 'alerta', 'ameaÃ§a', 'amedrontar', 'angustia', 'angÃºstia', 'angustiadamente', 'ansiedade', 'ansioso', 'apavorar', 'apreender', 'apreensÃ£o', 'apreensivo', 'arrepio', 'assombrado', 'assombro', 'assustado', 'assustadoramente', 'atemorizar', 'aterrorizante', 'brutal', 'calafrio', 'chocado', 'chocante', 'consternado', 'covarde', 'cruel', 'crueldade', 'cruelmente', 'cuidado', 'cuidadosamente', 'cuidadoso', 'defender', 'defensor', 'defesa', 'derrotar', 'desconfiado', 'desconfianÃ§a', 'desencorajar', 'desespero', 'deter', 'envergonhado', 'escandalizado', 'escuridÃ£o', 'espantoso', 'estremecedor', 'estremecer', 'expulsar', 'feio', 'friamente', 'fugir', 'hesitar', 'horrendo', 'horripilante', 'horrÃ­vel', 'horrivelmente', 'horror', 'horrorizar', 'impaciÃªncia', 'impaciente', 'impiedade', 'impiedoso', 'indecisÃ£o', 'inquieto', 'inseguranÃ§a', 'inseguro', 'intimidar', 'medonho', 'medroso', 'monstruosamente', 'mortalha', 'nervoso', 'pÃ¢nico', 'pavor', 'premoniÃ§Ã£o', 'preocupar', 'pressÃ¡gio', 'pressentimento', 'recear', 'receativamente', 'receio', 'receoso', 'ruim', 'suspeita', 'suspense', 'susto', 'temer', 'tenso', 'terror', 'tremor', 'temeroso', 'terrificar', 'timidamente', 'vigiar', 'temor', 'terrÃ­vel', 'timidez', 'vigilante', 'tensÃ£o', 'terrivelmente', 'tÃ­mido',]\n",
        "RAIVA = ['abominaÃ§Ã£o', 'aborrecer', 'adredido', 'agredir', 'agressÃ£o', 'agressivo', 'amaldiÃ§oado', 'amargor', 'amargura', 'amolar', 'angÃºstia', 'animosidade', 'antipatia', 'antipÃ¡tico', 'asco', 'assassinar', 'assassinato', 'assediar', 'assÃ©dio', 'atormentar', 'avarento', 'avareza', 'aversÃ£o', 'beligerante', 'bravejar', 'chateaÃ§Ã£o', 'chato', 'cobiÃ§oso', 'cÃ³lera', 'colÃ©rico', 'complicar', 'contraiedade', 'contrariar', 'corrupÃ§Ã£o', 'corrupto', 'cruxificar', 'demonÃ­aco', 'demÃ´nio', 'descaso', 'descontente', 'descontrole', 'desenganar', 'desgostar', 'desgraÃ§a', 'desprazer', 'desprezar', 'destruiÃ§Ã£o', 'destruir', 'detestar', 'diabo', 'diabÃ³lico', 'doido', 'encolerizar', 'energicamente', 'enfurecido', 'enfuriante', 'enlouquecer', 'enraivecer', 'escandalizar', 'escÃ¢ndalo', 'escoriar', 'exasperar', 'execraÃ§Ã£o', 'ferir', 'frustraÃ§Ã£o', 'frustrar', 'fÃºria', 'furioso', 'furor', 'ganÃ¢ncia', 'ganancioso', 'guerra', 'guerreador', 'guerrilha', 'hostil', 'humilhar', 'implicÃ¢ncia', 'implicar', 'importunar', 'incomodar', 'incÃ´modo', 'indignar', 'infernizar', 'inimigo', 'inimizade', 'injÃºria', 'injuriado', 'injustiÃ§a', 'insulto', 'malÃ­cia', 'odiÃ¡vel', 'repulsivo', 'inveja', 'malicioso', 'Ã³dio', 'resmungar', 'ira', 'malignidade', 'odioso', 'ressentido', 'irado', 'malÃ­gno', 'ofendido', 'revolta', 'irascibilidade', 'maltratar', 'ofensa', 'ridÃ­culo', 'irascÃ­vel', 'maluco', 'opressÃ£o', 'tempestuoso', 'irritar', 'malvadeza', 'opressivo', 'tirano', 'louco', 'malvado', 'oprimir', 'tormento', 'loucura', 'matar', 'perseguiÃ§Ã£o', 'torturar', 'magoar', 'mesquinho', 'perseguir', 'ultrage', 'mal', 'misantropia', 'perturbar', 'ultrajar', 'maldade', 'misantrÃ³pico', 'perverso', 'vexatÃ³rio', 'maldiÃ§Ã£o', 'molestar', 'provocar', 'vigoroso', 'maldito', 'molÃ©stia', 'rabugento', 'vinganÃ§a', 'maldizer', 'mortal', 'raivoso', 'vingar', 'maldoso', 'morte', 'rancor', 'vingativo', 'maleficÃªncia', 'mortÃ­fero', 'reclamar', 'violÃªncia', 'malÃ©fico', 'mortificar', 'repressÃ£o', 'violento', 'malevolÃªncia', 'nervoso', 'reprimir', 'zangar', 'malÃ©volo', 'odiar', 'repulsa',]\n",
        "SURPRESA = ['admirar', 'afeiÃ§Ã£o', 'apavorante', 'assombro', 'chocado', 'chocante', 'desconcertar', 'deslumbrar', 'embasbacar', 'emudecer', 'encantamento', 'enorme', 'espanto', 'estupefante', 'estupefato', 'estupefazer', 'expectativa', 'fantasticamente', 'fantÃ¡stico', 'horripilante', 'imaginÃ¡rio', 'imenso', 'impressionado', 'incrÃ­vel', 'maravilha', 'milagre', 'mistÃ©rio', 'misterioso', 'Ã³timo', 'pasmo', 'perplexo', 'prodÃ­gio', 'sensacional', 'surpreendente', 'surpreender', 'suspense', 'susto', 'temor', 'tremendo',]\n",
        "TRISTEZA = ['abandonar', 'abatido', 'abominÃ¡vel', 'aborrecer', 'abortar', 'afligir', 'aflito', 'afliÃ§Ã£o', 'agoniar', 'amargo', 'amargor', 'amargura', 'ansiedade', 'arrepender', 'arrependidamente', 'atrito', 'azar', 'cabisbaixo', 'choro', 'choroso', 'chorÃ£o', 'coitado', 'compassivo', 'compunÃ§Ã£o', 'contristador', 'contrito', 'contriÃ§Ã£o', 'culpa', 'defeituoso', 'degradante', 'deplorÃ¡vel', 'deposiÃ§Ã£o', 'depravado', 'depressivo', 'depressÃ£o', 'deprimente', 'deprimir', 'derrota', 'derrubar', 'desalentar', 'desamparo', 'desanimar', 'desapontar', 'desconsolo', 'descontente', 'desculpas', 'desencorajar', 'desespero', 'desgaste', 'desgosto', 'desgraÃ§a', 'desistir', 'desistÃªncia', 'deslocado', 'desmoralizar', 'desolar', 'desonra', 'despojado', 'desprazer', 'desprezo', 'desumano', 'desÃ¢nimo', 'discriminar', 'disforia', 'disfÃ³rico', 'dissuadir', 'doloroso', 'dor', 'dÃ³', 'enfadado', 'enlutar', 'entediado', 'entristecedor', 'entristecer', 'envergonhar', 'errante', 'erro', 'errÃ´neo', 'escurecer', 'escuridÃ£o', 'escuro', 'esquecido', 'estragado', 'execrÃ¡vel', 'extirpar', 'falsidade', 'falso', 'falta', 'fraco', 'fraqueza', 'fricÃ§Ã£o', 'frieza', 'frio', 'funesto', 'fÃºnebre', 'grave', 'horror', 'humilhar', 'inconsolÃ¡vel', 'indefeso', 'infelicidade', 'infeliz', 'infortÃºnio', 'isolar', 'lacrimejante', 'lacrimoso', 'lamentar', 'lastimoso', 'luto', 'lutoso', 'lÃ¡grima', 'lÃ¡stima', 'lÃºgubre', 'magoar', 'martirizar', 'martÃ­rio', 'mau', 'melancolia', 'melancÃ³lico', 'menosprezar', 'miseravelmente', 'misterioso', 'mistÃ©rio', 'misÃ©ria', 'morre', 'morte', 'mortificante', 'mÃ¡goa', 'negligentemente', 'nocivo', 'obscuro', 'opressivo', 'opressÃ£o', 'oprimir', 'pena', 'penalizar', 'penitente', 'penoso', 'penumbra', 'perder', 'perturbado', 'perverso', 'pervertar', 'pesaroso', 'pessimamente', 'piedade', 'pobre', 'porcamente', 'prejudicado', 'prejudicial', 'prejuÃ­zo', 'pressionar', 'pressÃ£o', 'quebrar', 'queda', 'queixoso', 'rechaÃ§ar', 'remorso', 'repressivo', 'repressÃ£o', 'reprimir', 'ruim', 'secreto', 'servil', 'sobrecarga', 'sobrecarregado', 'sofrer', 'sofrimento', 'solidÃ£o', 'sombrio', 'soturno', 'sujo', 'suplicar', 'suplÃ­cio', 'sÃ³', 'timidez', 'torturar', 'trevas', 'triste', 'tristemente', 'tÃ©dio', 'tÃ­mido', 'vazio',]\n",
        "\n",
        "emotion_words = {\n",
        "    'ALEGRIA': ALEGRIA,\n",
        "    'DESGOSTO': DESGOSTO,\n",
        "    'MEDO': MEDO,\n",
        "    'RAIVA': RAIVA,\n",
        "    'SURPRESA': SURPRESA,\n",
        "    'TRISTEZA': TRISTEZA,\n",
        "}\n",
        "for key, values in emotion_words.items():\n",
        "    for i, word in enumerate(values):\n",
        "        emotion_words[key][i] = ''.join([remover_acentos(p.strip()) for p in LOOKUP.get(word.lower(), word.lower())])\n",
        "# pp.pprint(emotion_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zf-PxyeIwi0g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "761a26af-3d15-463c-c3a2-ac94623d4992"
      },
      "cell_type": "code",
      "source": [
        "stpwords = stopwords.words('portuguese') + list(punctuation)\n",
        "rms = ['um', 'nÃ£o', 'mais', 'muito']\n",
        "for rm in rms:\n",
        "    del stpwords[stpwords.index(rm)]\n",
        "\n",
        "def tokenize_frases(frase):\n",
        "    return word_tokenize(remover_acentos(frase.lower()))\n",
        "\n",
        "def rm_stop_words_tokenized(frase):\n",
        "    frase = nlp(remover_acentos(frase.lower()))\n",
        "    clean_frase = []\n",
        "    for palavra in frase:\n",
        "        if palavra.pos_ != 'PUNCT':\n",
        "            palavra = palavra.lemma_\n",
        "            for pc in ['.', ',']:\n",
        "                palavra = palavra.replace(pc, '')\n",
        "            if palavra not in stpwords and not palavra.isdigit():\n",
        "                clean_frase.append(palavra)\n",
        "    return ' '.join(clean_frase)\n",
        "\n",
        "def generate_corpus(frases, tokenize=False):\n",
        "    print('Iniciando processamento...')\n",
        "    tokenized_frases = frases\n",
        "    with concurrent.futures.ProcessPoolExecutor(max_workers=4) as procs:\n",
        "        if tokenize:\n",
        "            print('Executando processo de tokenizaÃ§Ã£o das frases...')\n",
        "            tokenized_frases = procs.map(tokenize_frases, frases, chunksize=25)\n",
        "        print('Executando processo de remoÃ§Ã£o das stopwords...')\n",
        "        tokenized_frases = procs.map(rm_stop_words_tokenized, tokenized_frases, chunksize=25)\n",
        "    print('Filtro e finalizaÃ§Ã£o...')\n",
        "    return tokenized_frases\n",
        "\n",
        "\n",
        "frases = [\n",
        "    'Bom dia SENADOR, agora estÃ¡ claro porque o pedÃ¡gio nÃ£o baixava,o judiciÃ¡rio nÃ£o se manifestava quando era provocado e as CPIs sÃ³ serviram prÃ¡ corrupÃ§Ã£o,deu no que deu ðŸ™„',\n",
        "    'NÃ£o basta apenas retirar o candidato preferencial da maioria dos eleitores brasileiros. Tem que impedir tambÃ©m que esses mesmos eleitores possam comparecer Ã s urnas. Que democracia Ã© essa, minha gente? Poder judiciÃ¡rio comprometido atÃ© os cabelos com o golpe de destrÃ³i o paÃ­s.',\n",
        "    'Deus abenÃ§oe o dia de todos vocÃª, tenham um bom trabalho e bom estudo a todos. E pra aqueles que nÃ£o trabalha e nem estuda, boa curtiÃ§Ã£o em sua cama ðŸ™‚',\n",
        "    'Aprenda a ter amor prÃ³prio que nem essa banana q fez uma tatuagem dela mesma.',\n",
        "    'Estou muito feliz hoje',\n",
        "    'Dias chuvosos me deixam triste',\n",
        "    'Hoje o dia esta excelente',\n",
        "    'Tem certas coisas que eu nÃ£o como, acho bem nojento ficar mastigando lingua de boi por exemplo',\n",
        "    'Ã‰ de se admirar Ã queles que conseguem realizar boas aÃ§Ãµes sem desejar nada em troca',\n",
        "]\n",
        "\n",
        "# N = 10000\n",
        "\n",
        "# frases += [' '.join(f).replace('_', ' ') for f in flt.sents()[:250]]\n",
        "# frases += [' '.join(f).replace('_', ' ') for f in mch.sents()[:250]]\n",
        "# frases += [' '.join(f).replace('_', ' ') for f in mcm.sents()[:250]]\n",
        "\n",
        "frases = list(generate_corpus(frases, tokenize=False))\n",
        "# print(frases)\n",
        "\n",
        "ldocs = [f'D{i}' for i in range(len(frases))]"
      ],
      "execution_count": 479,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iniciando processamento...\n",
            "Executando processo de remoÃ§Ã£o das stopwords...\n",
            "Filtro e finalizaÃ§Ã£o...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7CXkPtuVzio8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "outputId": "fc9e98a2-09b0-42d7-e5fb-5d20ae4af4a8"
      },
      "cell_type": "code",
      "source": [
        "print('Tf-Idf:')\n",
        "vectorizer = TfidfVectorizer(max_df=1, sublinear_tf=True, use_idf=True, ngram_range=(1, 1))\n",
        "X_tfidf = vectorizer.fit_transform(frases)\n",
        "print(\"   Actual number of tfidf features: %d\" % X_tfidf.get_shape()[1])\n",
        "weights_tfidf = pd.DataFrame(np.round(X_tfidf.toarray().T, 3), index=vectorizer.get_feature_names(), columns=ldocs)\n",
        "display(weights_tfidf.head(15))"
      ],
      "execution_count": 480,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tf-Idf:\n",
            "   Actual number of tfidf features: 77\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>D0</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>abencoe</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.253</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>achar</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.302</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>acoes</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>admirar</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>agora</th>\n",
              "      <td>0.251</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>amor</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.378</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>apenas</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.201</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aprender</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.378</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>atar</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.201</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>baixar</th>\n",
              "      <td>0.251</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>banana</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.378</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>basto</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.201</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bem</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.302</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>boi</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.302</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>brasileiro</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.201</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               D0     D1     D2     D3   D4   D5   D6     D7     D8\n",
              "abencoe     0.000  0.000  0.253  0.000  0.0  0.0  0.0  0.000  0.000\n",
              "achar       0.000  0.000  0.000  0.000  0.0  0.0  0.0  0.302  0.000\n",
              "acoes       0.000  0.000  0.000  0.000  0.0  0.0  0.0  0.000  0.378\n",
              "admirar     0.000  0.000  0.000  0.000  0.0  0.0  0.0  0.000  0.378\n",
              "agora       0.251  0.000  0.000  0.000  0.0  0.0  0.0  0.000  0.000\n",
              "amor        0.000  0.000  0.000  0.378  0.0  0.0  0.0  0.000  0.000\n",
              "apenas      0.000  0.201  0.000  0.000  0.0  0.0  0.0  0.000  0.000\n",
              "aprender    0.000  0.000  0.000  0.378  0.0  0.0  0.0  0.000  0.000\n",
              "atar        0.000  0.201  0.000  0.000  0.0  0.0  0.0  0.000  0.000\n",
              "baixar      0.251  0.000  0.000  0.000  0.0  0.0  0.0  0.000  0.000\n",
              "banana      0.000  0.000  0.000  0.378  0.0  0.0  0.0  0.000  0.000\n",
              "basto       0.000  0.201  0.000  0.000  0.0  0.0  0.0  0.000  0.000\n",
              "bem         0.000  0.000  0.000  0.000  0.0  0.0  0.0  0.302  0.000\n",
              "boi         0.000  0.000  0.000  0.000  0.0  0.0  0.0  0.302  0.000\n",
              "brasileiro  0.000  0.201  0.000  0.000  0.0  0.0  0.0  0.000  0.000"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "GbRzyK7Zn4G6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "outputId": "e27eecfc-89f7-4f64-d363-6473fa485562"
      },
      "cell_type": "code",
      "source": [
        "print('Count:')\n",
        "vectorizer = CountVectorizer()\n",
        "X_count = vectorizer.fit_transform(frases)\n",
        "print(\"   Actual number of tfidf features: %d\" % X_count.get_shape()[1])\n",
        "weights_count = pd.DataFrame(X_count.toarray().T, index=vectorizer.get_feature_names(), columns=ldocs)\n",
        "display(weights_count.head(15))"
      ],
      "execution_count": 481,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count:\n",
            "   Actual number of tfidf features: 84\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>D0</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>abencoe</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>achar</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>acoes</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>admirar</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>agora</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>amor</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>apenas</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aprender</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>atar</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>baixar</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>banana</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>basto</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bem</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>boi</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bom</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          D0  D1  D2  D3  D4  D5  D6  D7  D8\n",
              "abencoe    0   0   1   0   0   0   0   0   0\n",
              "achar      0   0   0   0   0   0   0   1   0\n",
              "acoes      0   0   0   0   0   0   0   0   1\n",
              "admirar    0   0   0   0   0   0   0   0   1\n",
              "agora      1   0   0   0   0   0   0   0   0\n",
              "amor       0   0   0   1   0   0   0   0   0\n",
              "apenas     0   1   0   0   0   0   0   0   0\n",
              "aprender   0   0   0   1   0   0   0   0   0\n",
              "atar       0   1   0   0   0   0   0   0   0\n",
              "baixar     1   0   0   0   0   0   0   0   0\n",
              "banana     0   0   0   1   0   0   0   0   0\n",
              "basto      0   1   0   0   0   0   0   0   0\n",
              "bem        0   0   0   0   0   0   0   1   0\n",
              "boi        0   0   0   0   0   0   0   1   0\n",
              "bom        1   0   3   0   0   0   0   0   1"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "uvfJwFa8atEL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "29e10948-4a43-4c70-a58a-bb22a428aacf"
      },
      "cell_type": "code",
      "source": [
        "print('SVD: ')\n",
        "AC = copy.deepcopy(X_count.toarray().T)\n",
        "u, s, v = np.linalg.svd(AC, full_matrices=False)\n",
        "print('Original and SVD equals: ', np.allclose(AC, np.dot(u, np.dot(np.diag(s), v))))\n",
        "\n",
        "# print(AC)\n",
        "# print(u.astype(np.float16))\n",
        "# print('-' * 20)\n",
        "# print(np.diag(s.astype(np.float16)))\n",
        "# print('-' * 20)\n",
        "# print(v.astype(np.float16))"
      ],
      "execution_count": 482,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVD: \n",
            "Original and SVD equals:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "86EgpEoAJCEY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "outputId": "1d31ca28-a617-4422-fe3c-83888112fa22"
      },
      "cell_type": "code",
      "source": [
        "print('Matriz U:')\n",
        "weights_um = pd.DataFrame(u, index=vectorizer.get_feature_names(), columns=ldocs)\n",
        "display(weights_um.head(15))"
      ],
      "execution_count": 483,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matriz U:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>D0</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>abencoe</th>\n",
              "      <td>-0.121141</td>\n",
              "      <td>-0.078354</td>\n",
              "      <td>-0.107089</td>\n",
              "      <td>-0.015278</td>\n",
              "      <td>0.005196</td>\n",
              "      <td>0.044912</td>\n",
              "      <td>0.016150</td>\n",
              "      <td>-0.011787</td>\n",
              "      <td>-0.008395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>achar</th>\n",
              "      <td>-0.020953</td>\n",
              "      <td>0.009936</td>\n",
              "      <td>0.010063</td>\n",
              "      <td>0.272938</td>\n",
              "      <td>-0.065397</td>\n",
              "      <td>0.009375</td>\n",
              "      <td>-0.008330</td>\n",
              "      <td>0.005523</td>\n",
              "      <td>0.003251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>acoes</th>\n",
              "      <td>-0.014540</td>\n",
              "      <td>-0.011745</td>\n",
              "      <td>-0.010624</td>\n",
              "      <td>-0.015537</td>\n",
              "      <td>-0.137360</td>\n",
              "      <td>-0.330978</td>\n",
              "      <td>-0.022575</td>\n",
              "      <td>0.012702</td>\n",
              "      <td>0.006081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>admirar</th>\n",
              "      <td>-0.014540</td>\n",
              "      <td>-0.011745</td>\n",
              "      <td>-0.010624</td>\n",
              "      <td>-0.015537</td>\n",
              "      <td>-0.137360</td>\n",
              "      <td>-0.330978</td>\n",
              "      <td>-0.022575</td>\n",
              "      <td>0.012702</td>\n",
              "      <td>0.006081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>agora</th>\n",
              "      <td>-0.081228</td>\n",
              "      <td>-0.011599</td>\n",
              "      <td>0.188272</td>\n",
              "      <td>-0.026692</td>\n",
              "      <td>0.014662</td>\n",
              "      <td>-0.002089</td>\n",
              "      <td>0.021458</td>\n",
              "      <td>-0.015946</td>\n",
              "      <td>-0.011367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>amor</th>\n",
              "      <td>-0.006683</td>\n",
              "      <td>0.004699</td>\n",
              "      <td>-0.010784</td>\n",
              "      <td>0.049210</td>\n",
              "      <td>0.323950</td>\n",
              "      <td>-0.139611</td>\n",
              "      <td>-0.001515</td>\n",
              "      <td>0.000986</td>\n",
              "      <td>0.000596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>apenas</th>\n",
              "      <td>-0.062292</td>\n",
              "      <td>0.167098</td>\n",
              "      <td>-0.037964</td>\n",
              "      <td>-0.027951</td>\n",
              "      <td>-0.011140</td>\n",
              "      <td>0.001665</td>\n",
              "      <td>-0.003128</td>\n",
              "      <td>0.002280</td>\n",
              "      <td>0.001563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aprender</th>\n",
              "      <td>-0.006683</td>\n",
              "      <td>0.004699</td>\n",
              "      <td>-0.010784</td>\n",
              "      <td>0.049210</td>\n",
              "      <td>0.323950</td>\n",
              "      <td>-0.139611</td>\n",
              "      <td>-0.001515</td>\n",
              "      <td>0.000986</td>\n",
              "      <td>0.000596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>atar</th>\n",
              "      <td>-0.062292</td>\n",
              "      <td>0.167098</td>\n",
              "      <td>-0.037964</td>\n",
              "      <td>-0.027951</td>\n",
              "      <td>-0.011140</td>\n",
              "      <td>0.001665</td>\n",
              "      <td>-0.003128</td>\n",
              "      <td>0.002280</td>\n",
              "      <td>0.001563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>baixar</th>\n",
              "      <td>-0.081228</td>\n",
              "      <td>-0.011599</td>\n",
              "      <td>0.188272</td>\n",
              "      <td>-0.026692</td>\n",
              "      <td>0.014662</td>\n",
              "      <td>-0.002089</td>\n",
              "      <td>0.021458</td>\n",
              "      <td>-0.015946</td>\n",
              "      <td>-0.011367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>banana</th>\n",
              "      <td>-0.006683</td>\n",
              "      <td>0.004699</td>\n",
              "      <td>-0.010784</td>\n",
              "      <td>0.049210</td>\n",
              "      <td>0.323950</td>\n",
              "      <td>-0.139611</td>\n",
              "      <td>-0.001515</td>\n",
              "      <td>0.000986</td>\n",
              "      <td>0.000596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>basto</th>\n",
              "      <td>-0.062292</td>\n",
              "      <td>0.167098</td>\n",
              "      <td>-0.037964</td>\n",
              "      <td>-0.027951</td>\n",
              "      <td>-0.011140</td>\n",
              "      <td>0.001665</td>\n",
              "      <td>-0.003128</td>\n",
              "      <td>0.002280</td>\n",
              "      <td>0.001563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bem</th>\n",
              "      <td>-0.020953</td>\n",
              "      <td>0.009936</td>\n",
              "      <td>0.010063</td>\n",
              "      <td>0.272938</td>\n",
              "      <td>-0.065397</td>\n",
              "      <td>0.009375</td>\n",
              "      <td>-0.008330</td>\n",
              "      <td>0.005523</td>\n",
              "      <td>0.003251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>boi</th>\n",
              "      <td>-0.020953</td>\n",
              "      <td>0.009936</td>\n",
              "      <td>0.010063</td>\n",
              "      <td>0.272938</td>\n",
              "      <td>-0.065397</td>\n",
              "      <td>0.009375</td>\n",
              "      <td>-0.008330</td>\n",
              "      <td>0.005523</td>\n",
              "      <td>0.003251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bom</th>\n",
              "      <td>-0.459191</td>\n",
              "      <td>-0.258407</td>\n",
              "      <td>-0.143620</td>\n",
              "      <td>-0.088063</td>\n",
              "      <td>-0.107111</td>\n",
              "      <td>-0.198330</td>\n",
              "      <td>0.047333</td>\n",
              "      <td>-0.038604</td>\n",
              "      <td>-0.030473</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                D0        D1        D2        D3        D4        D5  \\\n",
              "abencoe  -0.121141 -0.078354 -0.107089 -0.015278  0.005196  0.044912   \n",
              "achar    -0.020953  0.009936  0.010063  0.272938 -0.065397  0.009375   \n",
              "acoes    -0.014540 -0.011745 -0.010624 -0.015537 -0.137360 -0.330978   \n",
              "admirar  -0.014540 -0.011745 -0.010624 -0.015537 -0.137360 -0.330978   \n",
              "agora    -0.081228 -0.011599  0.188272 -0.026692  0.014662 -0.002089   \n",
              "amor     -0.006683  0.004699 -0.010784  0.049210  0.323950 -0.139611   \n",
              "apenas   -0.062292  0.167098 -0.037964 -0.027951 -0.011140  0.001665   \n",
              "aprender -0.006683  0.004699 -0.010784  0.049210  0.323950 -0.139611   \n",
              "atar     -0.062292  0.167098 -0.037964 -0.027951 -0.011140  0.001665   \n",
              "baixar   -0.081228 -0.011599  0.188272 -0.026692  0.014662 -0.002089   \n",
              "banana   -0.006683  0.004699 -0.010784  0.049210  0.323950 -0.139611   \n",
              "basto    -0.062292  0.167098 -0.037964 -0.027951 -0.011140  0.001665   \n",
              "bem      -0.020953  0.009936  0.010063  0.272938 -0.065397  0.009375   \n",
              "boi      -0.020953  0.009936  0.010063  0.272938 -0.065397  0.009375   \n",
              "bom      -0.459191 -0.258407 -0.143620 -0.088063 -0.107111 -0.198330   \n",
              "\n",
              "                D6        D7        D8  \n",
              "abencoe   0.016150 -0.011787 -0.008395  \n",
              "achar    -0.008330  0.005523  0.003251  \n",
              "acoes    -0.022575  0.012702  0.006081  \n",
              "admirar  -0.022575  0.012702  0.006081  \n",
              "agora     0.021458 -0.015946 -0.011367  \n",
              "amor     -0.001515  0.000986  0.000596  \n",
              "apenas   -0.003128  0.002280  0.001563  \n",
              "aprender -0.001515  0.000986  0.000596  \n",
              "atar     -0.003128  0.002280  0.001563  \n",
              "baixar    0.021458 -0.015946 -0.011367  \n",
              "banana   -0.001515  0.000986  0.000596  \n",
              "basto    -0.003128  0.002280  0.001563  \n",
              "bem      -0.008330  0.005523  0.003251  \n",
              "boi      -0.008330  0.005523  0.003251  \n",
              "bom       0.047333 -0.038604 -0.030473  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "nEnQFBKQJF7b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "9c9ae988-68db-4a15-99e6-abe1691d4d82"
      },
      "cell_type": "code",
      "source": [
        "print('Matriz VT:')\n",
        "weights_vm = pd.DataFrame(v.T, columns=ldocs)\n",
        "display(weights_vm.head(15))"
      ],
      "execution_count": 484,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matriz VT:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>D0</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.504540</td>\n",
              "      <td>-0.062465</td>\n",
              "      <td>0.852810</td>\n",
              "      <td>-0.095001</td>\n",
              "      <td>0.040895</td>\n",
              "      <td>-0.005758</td>\n",
              "      <td>0.047515</td>\n",
              "      <td>-0.031736</td>\n",
              "      <td>-0.016029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.386923</td>\n",
              "      <td>0.899867</td>\n",
              "      <td>-0.171965</td>\n",
              "      <td>-0.099485</td>\n",
              "      <td>-0.031072</td>\n",
              "      <td>0.004590</td>\n",
              "      <td>-0.006926</td>\n",
              "      <td>0.004539</td>\n",
              "      <td>0.002205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.752453</td>\n",
              "      <td>-0.421957</td>\n",
              "      <td>-0.485079</td>\n",
              "      <td>-0.054378</td>\n",
              "      <td>0.014493</td>\n",
              "      <td>0.123808</td>\n",
              "      <td>0.035762</td>\n",
              "      <td>-0.023458</td>\n",
              "      <td>-0.011839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.041513</td>\n",
              "      <td>0.025304</td>\n",
              "      <td>-0.048847</td>\n",
              "      <td>0.175148</td>\n",
              "      <td>0.903571</td>\n",
              "      <td>-0.384861</td>\n",
              "      <td>-0.003355</td>\n",
              "      <td>0.001963</td>\n",
              "      <td>0.000840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.001053</td>\n",
              "      <td>-0.000777</td>\n",
              "      <td>0.001357</td>\n",
              "      <td>-0.002037</td>\n",
              "      <td>0.004359</td>\n",
              "      <td>0.010365</td>\n",
              "      <td>-0.625093</td>\n",
              "      <td>-0.664798</td>\n",
              "      <td>-0.408862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.037402</td>\n",
              "      <td>-0.020154</td>\n",
              "      <td>0.023620</td>\n",
              "      <td>-0.019270</td>\n",
              "      <td>0.019013</td>\n",
              "      <td>0.043164</td>\n",
              "      <td>-0.532904</td>\n",
              "      <td>0.745000</td>\n",
              "      <td>-0.395007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-0.036408</td>\n",
              "      <td>-0.019436</td>\n",
              "      <td>0.022418</td>\n",
              "      <td>-0.017655</td>\n",
              "      <td>0.016478</td>\n",
              "      <td>0.037306</td>\n",
              "      <td>-0.564657</td>\n",
              "      <td>0.026027</td>\n",
              "      <td>0.822377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-0.130147</td>\n",
              "      <td>0.053509</td>\n",
              "      <td>0.045582</td>\n",
              "      <td>0.971442</td>\n",
              "      <td>-0.182406</td>\n",
              "      <td>0.025844</td>\n",
              "      <td>-0.018445</td>\n",
              "      <td>0.010991</td>\n",
              "      <td>0.004585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-0.090313</td>\n",
              "      <td>-0.063251</td>\n",
              "      <td>-0.048125</td>\n",
              "      <td>-0.055299</td>\n",
              "      <td>-0.383129</td>\n",
              "      <td>-0.912398</td>\n",
              "      <td>-0.049989</td>\n",
              "      <td>0.025280</td>\n",
              "      <td>0.008575</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         D0        D1        D2        D3        D4        D5        D6  \\\n",
              "0 -0.504540 -0.062465  0.852810 -0.095001  0.040895 -0.005758  0.047515   \n",
              "1 -0.386923  0.899867 -0.171965 -0.099485 -0.031072  0.004590 -0.006926   \n",
              "2 -0.752453 -0.421957 -0.485079 -0.054378  0.014493  0.123808  0.035762   \n",
              "3 -0.041513  0.025304 -0.048847  0.175148  0.903571 -0.384861 -0.003355   \n",
              "4 -0.001053 -0.000777  0.001357 -0.002037  0.004359  0.010365 -0.625093   \n",
              "5 -0.037402 -0.020154  0.023620 -0.019270  0.019013  0.043164 -0.532904   \n",
              "6 -0.036408 -0.019436  0.022418 -0.017655  0.016478  0.037306 -0.564657   \n",
              "7 -0.130147  0.053509  0.045582  0.971442 -0.182406  0.025844 -0.018445   \n",
              "8 -0.090313 -0.063251 -0.048125 -0.055299 -0.383129 -0.912398 -0.049989   \n",
              "\n",
              "         D7        D8  \n",
              "0 -0.031736 -0.016029  \n",
              "1  0.004539  0.002205  \n",
              "2 -0.023458 -0.011839  \n",
              "3  0.001963  0.000840  \n",
              "4 -0.664798 -0.408862  \n",
              "5  0.745000 -0.395007  \n",
              "6  0.026027  0.822377  \n",
              "7  0.010991  0.004585  \n",
              "8  0.025280  0.008575  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "tCgjE9sRbKls",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "01a4238b-c5dc-4413-ec2f-0c54e19227c0"
      },
      "cell_type": "code",
      "source": [
        "# hmm-lda\n",
        "# https://ieeexplore.ieee.org/document/7363382\n",
        "# https://link.springer.com/chapter/10.1007/978-3-642-21802-6_57\n",
        "# http://www.ppgia.pucpr.br/~paraiso/Projects/Emocoes/Emocoes.html\n",
        "\n",
        "emotion_weigths = {}\n",
        "for k, items in enumerate(emotion_words.items()):\n",
        "    key, values = items\n",
        "    emotion_weigths[key] = []\n",
        "    for i, word in enumerate(values):\n",
        "        idx_val = 0\n",
        "        w = 0\n",
        "        try:\n",
        "            index = weights_count.index.get_loc(word)\n",
        "            idx_val = u[index]\n",
        "            w = weights_count.iloc[index].values\n",
        "        except:\n",
        "            w = np.zeros((len(ldocs, )))\n",
        "        emotion_weigths[key].append(np.mean(idx_val * w))\n",
        "# pp.pprint(emotion_weigths)\n",
        "\n",
        "values = np.zeros((277, 6))\n",
        "for k, val in enumerate(emotion_weigths.values()):\n",
        "    for t, va in enumerate(val):\n",
        "        values[t, k] = va\n",
        "df = pd.DataFrame(values, columns=emotion_weigths.keys())\n",
        "display(df[\n",
        "    (df['ALEGRIA'] != 0) | (df['DESGOSTO'] != 0) | (df['MEDO'] != 0) | \n",
        "    (df['RAIVA'] != 0) | (df['SURPRESA'] != 0) | (df['TRISTEZA'] != 0)\n",
        "])"
      ],
      "execution_count": 485,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ALEGRIA</th>\n",
              "      <th>DESGOSTO</th>\n",
              "      <th>MEDO</th>\n",
              "      <th>RAIVA</th>\n",
              "      <th>SURPRESA</th>\n",
              "      <th>TRISTEZA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000676</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.000676</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.005468</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.009025</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000614</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>-0.102280</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>0.000676</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>-0.028333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.009025</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>0.000174</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.009025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239</th>\n",
              "      <td>0.000676</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      ALEGRIA  DESGOSTO  MEDO     RAIVA  SURPRESA  TRISTEZA\n",
              "0    0.000000  0.000000   0.0  0.000000  0.000676  0.000000\n",
              "6    0.000676  0.000000   0.0  0.000000  0.000000  0.000000\n",
              "24   0.005468  0.000000   0.0  0.000000  0.000000  0.000000\n",
              "33   0.000000  0.000000   0.0 -0.009025  0.000000  0.000000\n",
              "44   0.000000  0.000614   0.0  0.000000  0.000000  0.000000\n",
              "56  -0.102280  0.000000   0.0  0.000000  0.000000  0.000000\n",
              "106  0.000676  0.000000   0.0  0.000000  0.000000  0.000000\n",
              "137 -0.028333  0.000000   0.0  0.000000  0.000000  0.000000\n",
              "138  0.000000  0.000000   0.0 -0.009025  0.000000  0.000000\n",
              "152  0.000174  0.000000   0.0  0.000000  0.000000  0.000000\n",
              "174  0.000000  0.000000   0.0  0.000000  0.000000 -0.009025\n",
              "178  0.000000  0.000000   0.0  0.000000  0.000000  0.001740\n",
              "239  0.000676  0.000000   0.0  0.000000  0.000000  0.000000"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "zctaT8xVmiJJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "d20be9c2-998c-4146-f798-2fd92baf075a"
      },
      "cell_type": "code",
      "source": [
        "print(v.T[5,])\n",
        "dtframe = {d: np.zeros(len(ldocs)) for d in emotion_weigths}\n",
        "for k, item in enumerate(emotion_weigths.items()):\n",
        "    sent = np.array(item[1])\n",
        "    i = 0\n",
        "    for j in range(len(ldocs)):\n",
        "        similarity = cosine_similarity(v.T, [sent])\n",
        "        for m in similarity:\n",
        "            i += 1\n",
        "            dtframe[item[0]][i-1] = m\n",
        "\n",
        "for frase in frases:\n",
        "    print(f'-{frase}')\n",
        "\n",
        "df = pd.DataFrame(list(dtframe.values()), index=dtframe.keys(), columns=ldocs)\n",
        "display(df.head(15))"
      ],
      "execution_count": 486,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.03740167 -0.02015354  0.02361973 -0.01927029  0.01901313  0.04316394\n",
            " -0.53290366  0.74499971 -0.3950066 ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-486-33e7558523cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mldocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m    915\u001b[0m     \u001b[0;31m# to avoid recursive import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0mX_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype)\u001b[0m\n\u001b[1;32m    121\u001b[0m         raise ValueError(\"Incompatible dimension for X and Y matrices: \"\n\u001b[1;32m    122\u001b[0m                          \"X.shape[1] == %d while Y.shape[1] == %d\" % (\n\u001b[0;32m--> 123\u001b[0;31m                              X.shape[1], Y.shape[1]))\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Incompatible dimension for X and Y matrices: X.shape[1] == 9 while Y.shape[1] == 277"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "x7TwnB5okQkL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xyW_HKxkwURE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "9277f0ea-40b5-45a2-8f93-f6656898a770"
      },
      "cell_type": "code",
      "source": [
        "print(\"LSA using TruncatedSVD:\")\n",
        "\n",
        "# Project the tfidf vectors onto the first N principal components.\n",
        "# Though this is significantly fewer features than the original tfidf vector,\n",
        "# they are stronger features, and the accuracy is higher.\n",
        "svd = TruncatedSVD(50)\n",
        "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
        "\n",
        "# Run SVD on the training data, then project the training data.\n",
        "X_lsa = lsa.fit_transform(X_count)\n",
        "\n",
        "explained_variance = svd.explained_variance_ratio_.sum()\n",
        "print(\"   Explained variance of the SVD step: {}%\".format(int(explained_variance * 100)))\n",
        "\n",
        "print(svd.explained_variance_.shape)\n",
        "print(svd.singular_values_.shape) # S\n",
        "print(svd.components_.shape) # VT"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSA using TruncatedSVD:\n",
            "   Explained variance of the SVD step: 100%\n",
            "(4,)\n",
            "(4,)\n",
            "(4, 61)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZHnVMukg0oWu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "008bfebd-37e4-4bc8-9530-f96c9d250313"
      },
      "cell_type": "code",
      "source": [
        "print('LSA using numpy:')\n",
        "u, s, v = np.linalg.svd(X_tfidf.toarray(), full_matrices=False)\n",
        "print(u)\n",
        "print(s.shape)\n",
        "print(v.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSA using numpy:\n",
            "[[0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [1. 0. 0. 0.]]\n",
            "(4,)\n",
            "(4, 58)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_KCInH7aaUQp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "9bc73216-ab28-4f39-c1ed-2a39a7af4076"
      },
      "cell_type": "code",
      "source": [
        "print('LSA using scikit-learn randomized_svd:')\n",
        "U, Sigma, VT = randomized_svd(X_count, \n",
        "                              n_components=50,\n",
        "                              n_iter=5,\n",
        "                              random_state=None)\n",
        "print(U.shape)\n",
        "print(Sigma.shape)\n",
        "print(VT.shape)\n",
        "\n",
        "print(U)\n",
        "# print(VT)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSA using scikit-learn randomized_svd:\n",
            "(4, 4)\n",
            "(4,)\n",
            "(4, 61)\n",
            "[[ 8.23887410e-02  4.64153487e-01  8.81914756e-01  0.00000000e+00]\n",
            " [ 9.96228666e-01 -6.25206048e-02 -6.01632624e-02 -3.70560802e-16]\n",
            " [ 2.72128558e-02  8.83545536e-01 -4.67554003e-01  2.07365235e-16]\n",
            " [ 3.63520293e-16 -2.06384313e-16  7.46602991e-17  1.00000000e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xy-B3w6obyOj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "b452f4f1-74d8-4410-937d-aeeff78b48f7"
      },
      "cell_type": "code",
      "source": [
        "# define a matrix\n",
        "# A = array([[1, 2], [3, 4], [5, 6]])\n",
        "A = np.array([\n",
        "    [1, 1, 1, 0, 0],\n",
        "    [3, 3, 3, 0, 0],\n",
        "    [4, 4, 4, 0, 0],\n",
        "    [5, 5, 5, 0, 0],\n",
        "    [0, 2, 0, 4, 4],\n",
        "    [0, 0, 0, 5, 5],\n",
        "    [0, 1, 0, 2, 2],\n",
        "])\n",
        "print(A.shape)\n",
        "\n",
        "\n",
        "u, s, v = np.linalg.svd(copy.deepcopy(A), full_matrices=False)\n",
        "\n",
        "print(u.astype(np.float16))\n",
        "print('-' * 20)\n",
        "print(np.diag(s.astype(np.float16)))\n",
        "print('-' * 20)\n",
        "print(v.astype(np.float16))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7, 5)\n",
            "[[-0.1376  -0.0236  -0.01081  0.56    -0.3757 ]\n",
            " [-0.4128  -0.07086 -0.03244  0.2064   0.756  ]\n",
            " [-0.5503  -0.0944  -0.04324 -0.7246  -0.1846 ]\n",
            " [-0.688   -0.11804 -0.05405  0.344   -0.2307 ]\n",
            " [-0.1528   0.5913   0.654    0.       0.2    ]\n",
            " [-0.0722   0.7314  -0.678    0.       0.     ]\n",
            " [-0.0764   0.2957   0.327    0.      -0.4    ]]\n",
            "--------------------\n",
            "[[12.484  0.     0.     0.     0.   ]\n",
            " [ 0.     9.51   0.     0.     0.   ]\n",
            " [ 0.     0.     1.346  0.     0.   ]\n",
            " [ 0.     0.     0.     0.     0.   ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "--------------------\n",
            "[[-0.5625  -0.593   -0.5625  -0.09015 -0.09015]\n",
            " [-0.1266   0.02878 -0.1266   0.6953   0.6953 ]\n",
            " [-0.4097   0.8047  -0.4097  -0.09125 -0.09125]\n",
            " [-0.707    0.       0.707    0.       0.     ]\n",
            " [ 0.      -0.       0.      -0.707    0.707  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0LFVgEqGyLRK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "99d47291-3c92-4804-a74f-3fd7c0174045"
      },
      "cell_type": "code",
      "source": [
        "u, s, v = randomized_svd(copy.deepcopy(A), \n",
        "                          power_iteration_normalizer='auto',\n",
        "                          flip_sign=True,\n",
        "                          n_components=100,\n",
        "                          n_iter=1,\n",
        "                          random_state=None)\n",
        "print(u.astype(np.float16))\n",
        "print('-' * 20)\n",
        "print(np.diag(s.astype(np.float16)))\n",
        "print('-' * 20)\n",
        "print(v.astype(np.float16))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.3757e-01 -2.3605e-02  1.0811e-02  9.3652e-01  2.8711e-01]\n",
            " [ 4.1284e-01 -7.0862e-02  3.2440e-02 -3.1152e-01  8.4912e-01]\n",
            " [ 5.5029e-01 -9.4421e-02  4.3243e-02  1.2622e-01 -2.9834e-01]\n",
            " [ 6.8799e-01 -1.1804e-01  5.4047e-02 -1.0132e-01 -3.2812e-01]\n",
            " [ 1.5283e-01  5.9131e-01 -6.5381e-01 -1.5199e-04 -6.2406e-05]\n",
            " [ 7.2205e-02  7.3145e-01  6.7822e-01  0.0000e+00  0.0000e+00]\n",
            " [ 7.6416e-02  2.9565e-01 -3.2690e-01  3.0398e-04  1.2481e-04]]\n",
            "--------------------\n",
            "[[12.484  0.     0.     0.     0.   ]\n",
            " [ 0.     9.51   0.     0.     0.   ]\n",
            " [ 0.     0.     1.346  0.     0.   ]\n",
            " [ 0.     0.     0.     0.     0.   ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "--------------------\n",
            "[[ 0.5625   0.593    0.5625   0.09015  0.09015]\n",
            " [-0.1266   0.02878 -0.1266   0.6953   0.6953 ]\n",
            " [ 0.4097  -0.8047   0.4097   0.09125  0.09125]\n",
            " [ 0.707    0.      -0.707   -0.      -0.     ]\n",
            " [-0.      -0.       0.       0.707   -0.707  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F4A5h4-8zNqm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "f91544f2-d7be-432e-dc8b-809779aea0dd"
      },
      "cell_type": "code",
      "source": [
        "u, s, v = svd(copy.deepcopy(A))\n",
        "print(u.astype(np.float16))\n",
        "print('-' * 20)\n",
        "print(np.diag(s.astype(np.float16)))\n",
        "print('-' * 20)\n",
        "print(v.astype(np.float16))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.1376  -0.0236  -0.01081  0.56    -0.3757  -0.7     -0.1879 ]\n",
            " [-0.4128  -0.07086 -0.03244  0.2064   0.756   -0.258    0.378  ]\n",
            " [-0.5503  -0.0944  -0.04324 -0.7246  -0.1846  -0.344   -0.0923 ]\n",
            " [-0.688   -0.11804 -0.05405  0.344   -0.2307   0.57    -0.11536]\n",
            " [-0.1528   0.5913   0.654    0.       0.2      0.      -0.4    ]\n",
            " [-0.0722   0.7314  -0.678    0.       0.       0.       0.     ]\n",
            " [-0.0764   0.2957   0.327    0.      -0.4      0.       0.8    ]]\n",
            "--------------------\n",
            "[[12.484  0.     0.     0.     0.   ]\n",
            " [ 0.     9.51   0.     0.     0.   ]\n",
            " [ 0.     0.     1.346  0.     0.   ]\n",
            " [ 0.     0.     0.     0.     0.   ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "--------------------\n",
            "[[-0.5625  -0.593   -0.5625  -0.09015 -0.09015]\n",
            " [-0.1266   0.02878 -0.1266   0.6953   0.6953 ]\n",
            " [-0.4097   0.8047  -0.4097  -0.09125 -0.09125]\n",
            " [-0.707    0.       0.707    0.       0.     ]\n",
            " [ 0.      -0.       0.      -0.707    0.707  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EmepFJucztDU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "fe87e36b-0a46-4753-f535-97309438db11"
      },
      "cell_type": "code",
      "source": [
        "# SVD\n",
        "U, s, VT = svd(A)\n",
        "print(U.astype(np.float16))\n",
        "print(np.diag(s.astype(np.float16)))\n",
        "print(VT.astype(np.float16))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.1376  -0.0236  -0.01081  0.56    -0.3757  -0.7     -0.1879 ]\n",
            " [-0.4128  -0.07086 -0.03244  0.2064   0.756   -0.258    0.378  ]\n",
            " [-0.5503  -0.0944  -0.04324 -0.7246  -0.1846  -0.344   -0.0923 ]\n",
            " [-0.688   -0.11804 -0.05405  0.344   -0.2307   0.57    -0.11536]\n",
            " [-0.1528   0.5913   0.654    0.       0.2      0.      -0.4    ]\n",
            " [-0.0722   0.7314  -0.678    0.       0.       0.       0.     ]\n",
            " [-0.0764   0.2957   0.327    0.      -0.4      0.       0.8    ]]\n",
            "[[12.484  0.     0.     0.     0.   ]\n",
            " [ 0.     9.51   0.     0.     0.   ]\n",
            " [ 0.     0.     1.346  0.     0.   ]\n",
            " [ 0.     0.     0.     0.     0.   ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "[[-0.5625  -0.593   -0.5625  -0.09015 -0.09015]\n",
            " [-0.1266   0.02878 -0.1266   0.6953   0.6953 ]\n",
            " [-0.4097   0.8047  -0.4097  -0.09125 -0.09125]\n",
            " [-0.707    0.       0.707    0.       0.     ]\n",
            " [ 0.      -0.       0.      -0.707    0.707  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RZoerdmc3Bbh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "outputId": "b02defdb-2313-45ec-d392-fa827e97a3b6"
      },
      "cell_type": "code",
      "source": [
        "A = [\n",
        "    [1, 2],\n",
        "    [3, 4],\n",
        "    [5, 6],\n",
        "    [7, 8]\n",
        "]\n",
        "\n",
        "U, s, VT = svd(A)\n",
        "print(U.astype(np.float16))\n",
        "print(np.diag(s.astype(np.float16)))\n",
        "print(VT.T.astype(np.float16))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.1525  -0.8228  -0.3945  -0.38   ]\n",
            " [-0.3499  -0.4214   0.2428   0.801  ]\n",
            " [-0.5474  -0.0201   0.6978  -0.4614 ]\n",
            " [-0.7446   0.381   -0.5464   0.04074]]\n",
            "[[14.266  0.   ]\n",
            " [ 0.     0.627]]\n",
            "[[-0.6416  0.767 ]\n",
            " [-0.767  -0.6416]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uK2Thy4WLSeo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "983b2701-163d-4d3d-afa2-a2982748d01a"
      },
      "cell_type": "code",
      "source": [
        "A = [\n",
        "    [2, 4],\n",
        "    [1, 3],\n",
        "    [0, 0],\n",
        "    [0, 0]\n",
        "    # [0, -1],\n",
        "    # [-2, 1],\n",
        "    # [1, 0]\n",
        "]\n",
        "\n",
        "U, s, VT = svd(A, full_matrices=False)\n",
        "print(U.astype(np.float16))\n",
        "print(np.diag(s.astype(np.float16)))\n",
        "print(VT.T.astype(np.float16))\n",
        "\n",
        "print(np.dot(U, U.T).astype(np.float16))\n",
        "print(np.dot(VT, VT.T).astype(np.float16))\n",
        "\n",
        "\n",
        "print(np.allclose(A, np.dot(U, np.dot(np.diag(s), VT))))\n",
        "\n",
        "print(np.dot(U, np.dot(np.diag(s), VT)).astype(np.float16))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.8174 -0.576 ]\n",
            " [-0.576   0.8174]\n",
            " [ 0.      0.    ]\n",
            " [ 0.      0.    ]]\n",
            "[[5.465 0.   ]\n",
            " [0.    0.366]]\n",
            "[[-0.4045 -0.9146]\n",
            " [-0.9146  0.4045]]\n",
            "[[ 1. -0.  0.  0.]\n",
            " [-0.  1.  0.  0.]\n",
            " [ 0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.]]\n",
            "[[ 1. -0.]\n",
            " [-0.  1.]]\n",
            "True\n",
            "[[2. 4.]\n",
            " [1. 3.]\n",
            " [0. 0.]\n",
            " [0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GT2PeZ_bQH0J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}